# matsushibadenki/snn2/snn_research/cognitive_architecture/emergent_system.py
# Phase 6: è¤‡æ•°ã®å°‚é–€å®¶SNNã‚’çµ±åˆã—ã€æ–°ãŸãªæ¦‚å¿µã‚’å‰µç™ºã•ã›ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
#
# æ©Ÿèƒ½:
# - è¤‡æ•°ã®å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã‚’çµ±åˆã—ã€ã‚ˆã‚Šé«˜æ¬¡ã®åˆ¤æ–­ã‚’ä¸‹ã™ã€‚
# - å€‹ã€…ã®å°‚é–€å®¶ã§ã¯èª¬æ˜Žã§ããªã„ï¼ˆäºˆæ¸¬èª¤å·®ãŒå¤§ãã„ï¼‰å ´åˆã«ã€ãã‚Œã‚‰ã‚’
#   çµ±åˆã™ã‚‹æ–°ã—ã„æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚’æ¤œçŸ¥ã™ã‚‹ã€‚
# - å°†æ¥çš„ã«ã¯ã€æ–°ã—ã„ä¸Šä½ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå·±çµ„ç¹”åŒ–ã™ã‚‹å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã€‚

from typing import List, Dict, Any, Optional
from snn_research.deployment import SNNInferenceEngine
from snn_research.distillation.model_registry import ModelRegistry

class EmergentSystem:
    """
    è¤‡æ•°ã®å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’ç«¶åˆãƒ»å”èª¿ã•ã›ã€
    å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è¶…ãˆã‚‹å‰µç™ºçš„ãªè§£ã‚’ç”Ÿæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚
    """
    def __init__(self, confidence_threshold: float = 0.7):
        self.registry = ModelRegistry()
        self.active_specialists: Dict[str, SNNInferenceEngine] = {}
        self.confidence_threshold = confidence_threshold

    def _load_specialists_for_domain(self, domain: str) -> List[SNNInferenceEngine]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆä¾‹: "è¨€èªžç†è§£"ï¼‰ã«é–¢é€£ã™ã‚‹å…¨ã¦ã®å°‚é–€å®¶ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
        """
        # ç¾çŠ¶ã¯ã‚¿ã‚¹ã‚¯å=ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ã—ã¦æ‰±ã†
        loaded_engines = []
        candidate_models = self.registry.find_models_for_task(domain)
        for model_info in candidate_models:
            path = model_info['model_path']
            if path not in self.active_specialists:
                # CPUã§ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„
                self.active_specialists[path] = SNNInferenceEngine(model_path=path, device="cpu")
            loaded_engines.append(self.active_specialists[path])
        return loaded_engines

    def synthesize_responses(self, prompt: str, domain: str) -> str:
        """
        ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã®å…¨å°‚é–€å®¶ã«åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã€ãã®å¿œç­”ã‚’çµ±åˆã™ã‚‹ã€‚
        """
        specialists = self._load_specialists_for_domain(domain)
        if not specialists:
            return f"ãƒ‰ãƒ¡ã‚¤ãƒ³ã€Œ{domain}ã€ã«é–¢ã™ã‚‹å°‚é–€å®¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        responses: List[Dict[str, Any]] = []
        print(f"ðŸŒŸ å‰µç™ºã‚·ã‚¹ãƒ†ãƒ ãŒ {len(specialists)} äººã®å°‚é–€å®¶ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³: {domain}ï¼‰ã«æ„è¦‹ã‚’æ±‚ã‚ã¦ã„ã¾ã™...")

        for i, engine in enumerate(specialists):
            full_response = ""
            # generateã¯ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãªã®ã§ã€å†…å®¹ã‚’çµåˆã™ã‚‹
            for chunk in engine.generate(prompt, max_len=50):
                full_response += chunk
            
            # å¿œç­”ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®— (ãƒ€ãƒŸãƒ¼ãƒ­ã‚¸ãƒƒã‚¯)
            # ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ãŒå°‘ãªã„ã»ã©åŠ¹çŽ‡çš„ã§ç¢ºä¿¡åº¦ãŒé«˜ã„ã¨ä»®å®š
            total_spikes = engine.last_inference_stats.get("total_spikes", 1000)
            confidence = 1.0 - (1 / (1 + (1000 / (total_spikes + 1e-5))))
            
            print(f"  - å°‚é–€å®¶ {i+1} ã®å¿œç­”: ã€Œ{full_response.strip()}ã€ (ä¿¡é ¼åº¦: {confidence:.2f})")
            responses.append({"text": full_response.strip(), "confidence": confidence})

        # å¿œç­”ã®çµ±åˆãƒ­ã‚¸ãƒƒã‚¯
        # æœ€ã‚‚ä¿¡é ¼åº¦ã®é«˜ã„å¿œç­”ã‚’é¸æŠžã™ã‚‹
        best_response = max(responses, key=lambda r: r['confidence'])

        # å¿œç­”ã®å¤šæ§˜æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        response_texts = {r['text'] for r in responses}
        if len(response_texts) > 1 and best_response['confidence'] < self.confidence_threshold:
            conflicting_info = (
                f"å°‚é–€å®¶ã®é–“ã§æ„è¦‹ã®å¯¾ç«‹ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚æœ€ã‚‚ç¢ºã‹ã‚‰ã—ã„å¿œç­”ã¯ã€Œ{best_response['text']}ã€ã§ã™ãŒã€"
                "ã“ã®å•é¡Œã«ã¯è¤‡æ•°ã®å´é¢ãŒã‚ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚ã‚ˆã‚Šé«˜æ¬¡ã®åˆ†æžãŒå¿…è¦ã§ã™ã€‚"
            )
            # å°†æ¥çš„ã«ã¯ã€ã“ã“ã§æ–°ã—ã„ä¸Šä½æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹
            self._trigger_new_concept_learning(domain, responses)
            return conflicting_info

        return best_response['text']

    def _trigger_new_concept_learning(self, domain: str, conflicting_responses: List[Dict[str, Any]]):
        """
        æ„è¦‹ã®å¯¾ç«‹ã‹ã‚‰ã€æ–°ã—ã„ä¸Šä½æ¦‚å¿µã®å­¦ç¿’ãŒå¿…è¦ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ã€
        å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã™ã‚‹ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰ã€‚
        """
        print(f"ðŸš¨ å‰µç™ºã‚·ã‚¹ãƒ†ãƒ : ãƒ‰ãƒ¡ã‚¤ãƒ³ã€Œ{domain}ã€ã«ãŠã„ã¦äºˆæ¸¬ã®ä¸ä¸€è‡´ã‚’æ¤œçŸ¥ã€‚")
        print("  - æ–°ã—ã„ä¸Šä½æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã®è‡ªå·±çµ„ç¹”åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        # (å°†æ¥çš„ãªå®Ÿè£…)
        # 1. å¯¾ç«‹ã—ãŸå¿œç­”ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ•´å½¢
        # 2. æ–°ã—ã„SNNãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        # 3. ã“ã‚Œã‚‰ã®å¿œç­”ã‚’çµ±åˆã§ãã‚‹ã‚ˆã†ã«è’¸ç•™å­¦ç¿’ã‚’å®Ÿè¡Œ
