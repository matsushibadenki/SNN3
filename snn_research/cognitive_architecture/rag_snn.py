# snn_research/cognitive_architecture/rag_snn.py
# Phase 3: RAG-SNN (Retrieval-Augmented Generation) ã‚·ã‚¹ãƒ†ãƒ 

import os
from typing import List, Optional
# â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader, TextLoader
# HuggingFaceEmbeddings ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå…ƒã‚’å¤‰æ›´
from langchain_huggingface import HuggingFaceEmbeddings
# â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
from langchain.text_splitter import RecursiveCharacterTextSplitter

class RAGSystem:
    """
    å¤–éƒ¨çŸ¥è­˜ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰ã¨å†…éƒ¨è¨˜æ†¶ï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ­ã‚°ï¼‰ã‚’æ¤œç´¢ã—ã€
    æ€è€ƒã®ãŸã‚ã®æ–‡è„ˆã‚’æä¾›ã™ã‚‹RAGã‚·ã‚¹ãƒ†ãƒ ã€‚
    """
    def __init__(self, vector_store_path: str = "runs/vector_store"):
        self.vector_store_path = vector_store_path
        self.embedding_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        self.vector_store: Optional[FAISS] = self._load_vector_store()

    def _load_vector_store(self) -> Optional[FAISS]:
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰èª­ã¿è¾¼ã‚€ã€‚"""
        if os.path.exists(self.vector_store_path):
            print(f"ğŸ“š æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {self.vector_store_path}")
            return FAISS.load_local(self.vector_store_path, self.embedding_model, allow_dangerous_deserialization=True)
        return None

    def setup_vector_store(self, knowledge_dir: str = "doc", memory_file: str = "runs/agent_memory.jsonl"):
        """
        çŸ¥è­˜æºã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ãƒ»ä¿å­˜ã™ã‚‹ã€‚
        """
        print("ğŸ› ï¸ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆ.md, .txtï¼‰ã‚’èª­ã¿è¾¼ã‚€
        doc_loader = DirectoryLoader(
            knowledge_dir, glob="**/*.md", loader_cls=TextLoader, silent_errors=True
        )
        txt_loader = DirectoryLoader(
            knowledge_dir, glob="**/*.txt", loader_cls=TextLoader, silent_errors=True
        )
        docs = doc_loader.load() + txt_loader.load()

        # 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨˜æ†¶ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
        if os.path.exists(memory_file):
            memory_loader = TextLoader(memory_file)
            docs.extend(memory_loader.load())
        
        if not docs:
            print("âš ï¸ çŸ¥è­˜æºã¨ãªã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return

        # 3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        split_docs = text_splitter.split_documents(docs)

        # 4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        print(f"ğŸ“„ {len(split_docs)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ã„ã¾ã™...")
        self.vector_store = FAISS.from_documents(split_docs, self.embedding_model)
        
        # 5. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã«ä¿å­˜
        os.makedirs(os.path.dirname(self.vector_store_path), exist_ok=True)
        self.vector_store.save_local(self.vector_store_path)
        print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã€'{self.vector_store_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    def search(self, query: str, k: int = 3) -> List[str]:
        """
        ã‚¯ã‚¨ãƒªã«æœ€ã‚‚é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’æ¤œç´¢ã™ã‚‹ã€‚
        """
        if self.vector_store is None:
            print("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã« setup_vector_store() ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            # ãƒ©ã‚¤ãƒ–ã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’è©¦ã¿ã‚‹
            self.setup_vector_store()
            if self.vector_store is None:
                 return ["ã‚¨ãƒ©ãƒ¼: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ§‹ç¯‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"]

        results = self.vector_store.similarity_search(query, k=k)
        return [doc.page_content for doc in results]
