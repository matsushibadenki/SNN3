# matsushibadenki/snn3/snn_research/cognitive_architecture/hierarchical_planner.py
# Title: éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼
# Description: é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã‚’ã€å®Ÿè¡Œå¯èƒ½ãªã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆ†è§£ã™ã‚‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: ModelRegistryã®å…·è±¡ã‚¯ãƒ©ã‚¹ã‚’DIã§å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´ã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: å­˜åœ¨ã—ãªã„`registry`å±æ€§ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å‰Šé™¤ã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: planner_modelã‚’Optionalã«å¤‰æ›´ã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: snn-cli.pyã‹ã‚‰ã®å‘¼ã³å‡ºã—ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€execute_taskãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ ã€‚
# æ”¹å–„ç‚¹: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸè¨ˆç”»ç«‹æ¡ˆãƒ­ã‚¸ãƒƒã‚¯ã‚’ã€å­¦ç¿’æ¸ˆã¿PlannerSNNã‚’åˆ©ç”¨ã™ã‚‹å½¢å¼ã«ç½®ãæ›ãˆã€‚
#         Tokenizerã‚’ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ã§å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: .item()ãŒè¿”ã™å‹ã®æ›–æ˜§ã•ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€int()ã§ã‚­ãƒ£ã‚¹ãƒˆã™ã‚‹ã€‚
# æ”¹å–„ç‚¹: RAGSystemã‚’çµ±åˆã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã«ã‚ˆã‚‹æ–‡è„ˆç”Ÿæˆæ©Ÿèƒ½ã‚’è¿½åŠ ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: asyncioã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã€‚
# æ”¹å–„ç‚¹: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«æ—¥æœ¬èªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ ã€‚

from typing import List, Dict, Any, Optional
import torch
from transformers import AutoTokenizer
import asyncio

from .planner_snn import PlannerSNN
from snn_research.distillation.model_registry import ModelRegistry
from .rag_snn import RAGSystem

class Plan:
    """
    ã‚¿ã‚¹ã‚¯ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, goal: str, task_list: List[Dict[str, Any]]):
        self.goal = goal
        self.task_list = task_list

    def __repr__(self) -> str:
        return f"Plan(goal='{self.goal}', tasks={len(self.task_list)})"


class HierarchicalPlanner:
    """
    é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã™ã‚‹éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€‚
    PlannerSNNã¨RAGSystemã‚’å†…éƒ¨ã§åˆ©ç”¨ã—ã¦ã€å‹•çš„ã«è¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    def __init__(
        self,
        model_registry: ModelRegistry,
        rag_system: RAGSystem,
        planner_model: Optional[PlannerSNN] = None,
        tokenizer_name: str = "gpt2",
        device: str = "cpu"
    ):
        self.model_registry = model_registry
        self.rag_system = rag_system
        self.planner_model = planner_model
        # PlannerSNNãŒãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã™ã‚‹ãŸã‚ã«TokenizerãŒå¿…è¦
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        self.device = device
        if self.planner_model:
            self.planner_model.to(self.device)

        # ãƒ€ãƒŸãƒ¼ã®ã‚¹ã‚­ãƒ«ãƒªã‚¹ãƒˆï¼ˆå®Ÿéš›ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã«å¿œã˜ã¦è¦å¤‰æ›´ï¼‰
        self.SKILL_MAP: Dict[int, Dict[str, Any]] = {
            0: {"task": "summarization", "description": "Summarize the input text.", "expert_id": "expert_summarizer_v1"},
            1: {"task": "sentiment_analysis", "description": "Analyze the sentiment of the text.", "expert_id": "expert_sentiment_v2"},
            2: {"task": "translation", "description": "Translate the summary to Japanese.", "expert_id": "expert_translator_v1"},
            3: {"task": "web_search", "description": "Search the web for information.", "expert_id": "web_crawler"},
            4: {"task": "general_qa", "description": "Answer a general question.", "expert_id": "general_snn_v3"},
        }


    async def create_plan(self, high_level_goal: str, context: Optional[str] = None) -> Plan:
        """
        ç›®æ¨™ã«åŸºã¥ã„ã¦è¨ˆç”»ã‚’ä½œæˆã™ã‚‹ã€‚PlannerSNNãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã™ã‚‹ã€‚
        å¿…è¦ã«å¿œã˜ã¦RAGã‚·ã‚¹ãƒ†ãƒ ã§æ–‡è„ˆã‚’è£œå¼·ã™ã‚‹ã€‚
        """
        print(f"ğŸŒ Creating plan for goal: {high_level_goal}")

        # RAGã‚·ã‚¹ãƒ†ãƒ ã§é–¢é€£æƒ…å ±ã‚’æ¤œç´¢
        retrieved_context = self.rag_system.search(high_level_goal)
        full_prompt = f"Goal: {high_level_goal}\n\nRetrieved Context:\n{' '.join(retrieved_context)}"
        
        if context:
            full_prompt += f"\n\nUser Provided Context:\n{context}"

        if self.planner_model:
            # --- PlannerSNNã«ã‚ˆã‚‹å‹•çš„ãªè¨ˆç”»ç”Ÿæˆ ---
            self.planner_model.eval()
            with torch.no_grad():
                inputs = self.tokenizer(full_prompt, return_tensors="pt")
                input_ids = inputs['input_ids'].to(self.device)

                # PlannerSNNãŒã‚¹ã‚­ãƒ«IDã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’äºˆæ¸¬
                skill_logits, _, _ = self.planner_model(input_ids)
                
                # æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã‚¹ã‚­ãƒ«ã‚’ä¸€ã¤é¸æŠï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹äºˆæ¸¬ã¯å°†æ¥ã®æ‹¡å¼µï¼‰
                predicted_skill_id_val = torch.argmax(skill_logits, dim=-1).item()
                predicted_skill_id = int(predicted_skill_id_val)
                
                # äºˆæ¸¬ã•ã‚ŒãŸIDã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’æ§‹ç¯‰
                task = self.SKILL_MAP.get(predicted_skill_id, self.SKILL_MAP[4]) # ä¸æ˜ãªå ´åˆã¯æ±ç”¨QA
                task_list = [task]
                
                print(f"ğŸ§  PlannerSNN predicted skill ID: {predicted_skill_id} -> Task: {task['task']}")

        else:
            # --- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“çš„ãªè¨ˆç”»ç”Ÿæˆ ---
            print("âš ï¸ PlannerSNN model not found. Falling back to rule-based planning.")
            task_list = []
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
            if "summarize" in high_level_goal or "è¦ç´„" in high_level_goal:
                task_list.append(self.SKILL_MAP[0])
            if "analyze" in high_level_goal or "sentiment" in high_level_goal or "æ„Ÿæƒ…" in high_level_goal or "åˆ†æ" in high_level_goal:
                task_list.append(self.SKILL_MAP[1])
            if "translate" in high_level_goal or "ç¿»è¨³" in high_level_goal:
                task_list.append(self.SKILL_MAP[2])
            # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
            
            if not task_list:
                task_list.append(self.SKILL_MAP[4]) # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ±ç”¨QA

        print(f"âœ… Plan created with {len(task_list)} step(s).")
        return Plan(goal=high_level_goal, task_list=task_list)

    def execute_task(self, task_request: str, context: str) -> Optional[str]:
        """
        ã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’å—ã‘å–ã‚Šã€è¨ˆç”»ç«‹æ¡ˆã‹ã‚‰å®Ÿè¡Œã¾ã§ã‚’è¡Œã†ã€‚
        """
        print(f"Executing task: {task_request} with context: {context}")
        
        # éåŒæœŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’åŒæœŸçš„ã«å‘¼ã³å‡ºã™
        plan = asyncio.run(self.create_plan(task_request, context))
        
        # ToDo: å®Ÿéš›ã«ãƒ—ãƒ©ãƒ³ã®ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦å°‚é–€å®¶SNNã‚’å®Ÿè¡Œã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…
        # ã“ã“ã§ã¯ãƒ—ãƒ©ãƒ³ã®å†…å®¹ã‚’è¿”ã™ãƒ€ãƒŸãƒ¼å®Ÿè£…
        if plan.task_list:
            final_result = f"Plan for '{task_request}':\n"
            for i, task in enumerate(plan.task_list):
                final_result += f"  Step {i+1}: Execute '{task['task']}' using expert '{task['expert_id']}'.\n"
            final_result += "Task completed successfully (dummy execution)."
            return final_result
        else:
            return "Could not create a plan for the given task."
