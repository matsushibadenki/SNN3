# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: matsushibadenki/snn3/SNN3-190ede29139f560c909685675a68ccf65069201c/snn_research/cognitive_architecture/hierarchical_planner.py
#
# Title: éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼
#
# æ”¹å–„ç‚¹:
# - ROADMAPãƒ•ã‚§ãƒ¼ã‚º8ã«åŸºã¥ãã€å”èª¿çš„ã‚¿ã‚¹ã‚¯è§£æ±ºã®ãŸã‚ã®`refine_plan`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã€‚
# - ã‚¿ã‚¹ã‚¯å¤±æ•—æ™‚ã«ã€ä»£æ›¿ã¨ãªã‚‹å°‚é–€å®¶ï¼ˆå”åŠ›è€…ï¼‰ã‚’ææ¡ˆã™ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚
#
# æ”¹å–„ç‚¹ (v2):
# - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’å»ƒæ­¢ã—ã€ModelRegistryã‹ã‚‰å‹•çš„ã«ã‚¹ã‚­ãƒ«ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ã€‚

from typing import List, Dict, Any, Optional
import torch
from transformers import AutoTokenizer
import asyncio

from .planner_snn import PlannerSNN
from snn_research.distillation.model_registry import ModelRegistry
from .rag_snn import RAGSystem

class Plan:
    """
    ã‚¿ã‚¹ã‚¯ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’è¡¨ç¾ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, goal: str, task_list: List[Dict[str, Any]]):
        self.goal = goal
        self.task_list = task_list

    def __repr__(self) -> str:
        return f"Plan(goal='{self.goal}', tasks={len(self.task_list)})"


class HierarchicalPlanner:
    """
    é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã‚’ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã™ã‚‹éšå±¤å‹ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€‚
    PlannerSNNã¨RAGSystemã‚’å†…éƒ¨ã§åˆ©ç”¨ã—ã¦ã€å‹•çš„ã«è¨ˆç”»ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    def __init__(
        self,
        model_registry: ModelRegistry,
        rag_system: RAGSystem,
        planner_model: Optional[PlannerSNN] = None,
        tokenizer_name: str = "gpt2",
        device: str = "cpu"
    ):
        self.model_registry = model_registry
        self.rag_system = rag_system
        self.planner_model = planner_model
        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)
        self.device = device
        if self.planner_model:
            self.planner_model.to(self.device)

        # æ”¹å–„: ModelRegistryã‹ã‚‰å‹•çš„ã«ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’æ§‹ç¯‰
        self.SKILL_MAP: Dict[int, Dict[str, Any]] = asyncio.run(self._build_skill_map())
        print(f"ğŸ§  Planner initialized with {len(self.SKILL_MAP)} skills from the registry.")

    async def _build_skill_map(self) -> Dict[int, Dict[str, Any]]:
        """ãƒ¢ãƒ‡ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰å‹•çš„ã«ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’æ§‹ç¯‰ã™ã‚‹"""
        all_models = await self.model_registry.list_models()
        skill_map = {}
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æ±ç”¨ã‚¹ã‚­ãƒ«
        fallback_skill = {
            "task": "general_qa", 
            "description": "Answer a general question.", 
            "expert_id": "general_snn_v3"
        }
        
        # ç™»éŒ²æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚­ãƒ«ã¨ã—ã¦è¿½åŠ 
        for i, model_info in enumerate(all_models):
            skill_map[i] = {
                "task": model_info.get("model_id"),
                "description": model_info.get("task_description"),
                "expert_id": model_info.get("model_id")
            }
        
        # æ±ç”¨ã‚¹ã‚­ãƒ«ãŒãªã‘ã‚Œã°è¿½åŠ 
        if not any(skill['task'] == 'general_qa' for skill in skill_map.values()):
            skill_map[len(skill_map)] = fallback_skill
            
        return skill_map

    async def create_plan(self, high_level_goal: str, context: Optional[str] = None) -> Plan:
        """
        ç›®æ¨™ã«åŸºã¥ã„ã¦è¨ˆç”»ã‚’ä½œæˆã™ã‚‹ã€‚PlannerSNNãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã™ã‚‹ã€‚
        RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’æ´»ç”¨ã—ã¦ã€è¨˜å·æ¨è«–ã«åŸºã¥ã„ãŸè¨ˆç”»ã‚’è©¦ã¿ã‚‹ã€‚
        """
        print(f"ğŸŒ Creating plan for goal: {high_level_goal}")

        # ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’å‹•çš„ã«æ›´æ–°
        self.SKILL_MAP = await self._build_skill_map()

        knowledge_query = f"Find concepts and relations for: {high_level_goal}"
        retrieved_knowledge = self.rag_system.search(knowledge_query, k=5)
        
        full_prompt = f"Goal: {high_level_goal}\n\nRetrieved Knowledge:\n{' '.join(retrieved_knowledge)}"
        if context:
            full_prompt += f"\n\nUser Provided Context:\n{context}"
        
        print(f"ğŸ§  Planner is reasoning with prompt: {full_prompt[:200]}...")

        if self.planner_model and len(self.SKILL_MAP) > 0:
            self.planner_model.eval()
            with torch.no_grad():
                inputs = self.tokenizer(full_prompt, return_tensors="pt")
                input_ids = inputs['input_ids'].to(self.device)
                skill_logits, _, _ = self.planner_model(input_ids)
                predicted_skill_id = int(torch.argmax(skill_logits, dim=-1).item())
                
                # ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã®ç¯„å›²å†…ã«IDãŒã‚ã‚‹ã‹ç¢ºèª
                if predicted_skill_id in self.SKILL_MAP:
                    task = self.SKILL_MAP[predicted_skill_id]
                    task_list = [task]
                    print(f"ğŸ§  PlannerSNN predicted skill ID: {predicted_skill_id} -> Task: {task.get('task')}")
                else:
                    print(f"âš ï¸ PlannerSNN predicted an invalid skill ID: {predicted_skill_id}. Falling back to rule-based planning.")
                    task_list = self._create_rule_based_plan(full_prompt)
        else:
            print("âš ï¸ PlannerSNN model not found or no skills available. Falling back to rule-based planning.")
            task_list = self._create_rule_based_plan(full_prompt)

        print(f"âœ… Plan created with {len(task_list)} step(s).")
        return Plan(goal=high_level_goal, task_list=task_list)

    def _create_rule_based_plan(self, prompt: str) -> List[Dict[str, Any]]:
        """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç°¡æ˜“çš„ãªè¨ˆç”»ã‚’ä½œæˆã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰ã€‚"""
        task_list = []
        prompt_lower = prompt.lower()
        
        # åˆ©ç”¨å¯èƒ½ãªã‚¹ã‚­ãƒ«ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢
        available_skills = list(self.SKILL_MAP.values())
        
        for skill in available_skills:
            task_keywords = skill.get('task', '').lower().split('_')
            desc_keywords = skill.get('description', '').lower().split()
            
            if any(kw in prompt_lower for kw in task_keywords if kw) or any(kw in prompt_lower for kw in desc_keywords if kw):
                 if skill not in task_list:
                    task_list.append(skill)

        if not task_list:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ±ç”¨QAã‚¹ã‚­ãƒ«ã‚’æ¢ã™
            fallback_skill = next((s for s in available_skills if "general" in s.get("task", "")), None)
            if fallback_skill:
                task_list.append(fallback_skill)
        
        return task_list


    async def refine_plan(self, failed_task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å¤±æ•—ã—ãŸã‚¿ã‚¹ã‚¯ã®ä»£æ›¿æ¡ˆï¼ˆå”åŠ›è€…ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚
        """
        task_desc = failed_task.get("description", "")
        print(f"ğŸ¤” Refining plan for failed task: {task_desc}")

        alternative_experts = await self.model_registry.find_models_for_task(task_desc, top_k=5)

        original_expert_id = failed_task.get("expert_id")
        for expert in alternative_experts:
            if expert.get("model_id") != original_expert_id:
                print(f"âœ… Found alternative expert: {expert['model_id']}")
                new_task = failed_task.copy()
                new_task["expert_id"] = expert["model_id"]
                new_task["description"] = expert["task_description"]
                return new_task
        
        print("âŒ No alternative expert found.")
        return None

    def execute_task(self, task_request: str, context: str) -> Optional[str]:
        """
        ã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’å—ã‘å–ã‚Šã€è¨ˆç”»ç«‹æ¡ˆã‹ã‚‰å®Ÿè¡Œã¾ã§ã‚’è¡Œã†ã€‚
        """
        print(f"Executing task: {task_request} with context: {context}")
        
        plan = asyncio.run(self.create_plan(task_request, context))
        
        if plan.task_list:
            final_result = f"Plan for '{task_request}':\n"
            for i, task in enumerate(plan.task_list):
                final_result += f"  Step {i+1}: Execute '{task.get('task')}' using expert '{task.get('expert_id')}'.\n"
            final_result += "Task completed successfully (dummy execution)."
            return final_result
        else:
            return "Could not create a plan for the given task."
