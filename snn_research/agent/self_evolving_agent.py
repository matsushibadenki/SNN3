# matsushibadenki/snn3/snn_research/agent/self_evolving_agent.py
#
# Title: è‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
#
# Description: è‡ªèº«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„å­¦ç¿’ãƒ«ãƒ¼ãƒ«ã‚’è‡ªå¾‹çš„ã«ä¿®æ­£ãƒ»æ”¹å–„ã§ãã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: super().__init__ã«å¼•æ•°ã‚’è¿½åŠ ã€‚
#              mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: snn-cli.pyã‹ã‚‰ã®å‘¼ã³å‡ºã—ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€ãƒ¡ã‚½ãƒƒãƒ‰ã¨å¼•æ•°ã‚’ä¿®æ­£ã€‚
# 
# æ”¹å–„ç‚¹: 
# - ãƒ€ãƒŸãƒ¼ã ã£ãŸevolveãƒ¡ã‚½ãƒƒãƒ‰ã«ã€è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¼·åŒ–ã—ã€
#   æ–°ã—ã„è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹å…·ä½“çš„ãªè‡ªå·±é€²åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã€‚
# - ROADMAP.mdã®ã€Œãƒ¡ã‚¿å¯å¡‘æ€§ã€ã«åŸºã¥ãã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã ã‘ã§ãªã
#   å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚é€²åŒ–ã•ã›ã‚‹æ©Ÿèƒ½ã‚’è¿½åŠ ã€‚

from typing import Dict, Any, Optional
import os
import yaml
from omegaconf import OmegaConf
import random

from .autonomous_agent import AutonomousAgent
from snn_research.cognitive_architecture.hierarchical_planner import HierarchicalPlanner
from snn_research.distillation.model_registry import ModelRegistry
from snn_research.tools.web_crawler import WebCrawler
from .memory import Memory as AgentMemory


class SelfEvolvingAgent(AutonomousAgent):
    """
    è‡ªèº«ã®æ€§èƒ½ã‚’ç›£è¦–ã—ã€å¿…è¦ã«å¿œã˜ã¦è‡ªå·±é€²åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
    """
    def __init__(
        self,
        name: str,
        planner: HierarchicalPlanner,
        model_registry: ModelRegistry,
        memory: AgentMemory,
        web_crawler: WebCrawler,
        evolution_threshold: float = 0.5,
        project_root: str = ".",
        model_config_path: Optional[str] = None,
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        training_config_path: Optional[str] = None,
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
    ):
        super().__init__(name, planner, model_registry, memory, web_crawler)
        self.evolution_threshold = evolution_threshold
        self.project_root = project_root
        self.model_config_path = model_config_path
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
        self.training_config_path = training_config_path
        # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸


    def execute(self, task_description: str) -> str:
        """
        ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è©•ä¾¡ã—ã¦è‡ªå·±é€²åŒ–ã‚’è©¦ã¿ã‚‹ã€‚
        """
        result = super().execute(task_description)
        
        # ç°¡æ˜“çš„ãªæ€§èƒ½è©•ä¾¡
        performance = self.evaluate_performance(task_description, result)
        
        if performance < self.evolution_threshold:
            print(f"ğŸ“‰ Performance ({performance:.2f}) is below threshold ({self.evolution_threshold}). Triggering evolution...")
            evolution_result = self.evolve()
            return f"{result}\nAdditionally, self-evolution was triggered: {evolution_result}"

        return result

    def evaluate_performance(self, task: str, result: str) -> float:
        """
        ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œçµæœã‚’è©•ä¾¡ã™ã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰ã€‚
        """
        if "successfully" in result.lower() or "using expert" in result.lower():
            return 0.9
        if "no specific expert found" in result.lower():
            return 0.4
        return 0.1

    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†“ä¿®æ­£é–‹å§‹â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸
    def evolve(self) -> str:
        """
        è‡ªå·±é€²åŒ–ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
        ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é€²åŒ–ã•ã›ã‚‹ã‹ã€å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é€²åŒ–ã•ã›ã‚‹ã‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®šã™ã‚‹ã€‚
        """
        if random.random() < 0.6:  # 60%ã®ç¢ºç‡ã§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é€²åŒ–
            return self._evolve_architecture()
        else:  # 40%ã®ç¢ºç‡ã§å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é€²åŒ–
            return self._evolve_learning_parameters()

    def _evolve_architecture(self) -> str:
        """ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é€²åŒ–ã•ã›ã‚‹ã€‚"""
        if not self.model_config_path or not os.path.exists(self.model_config_path):
            return "Architecture evolution failed: model_config_path is not set or file not found."

        try:
            print(f"ğŸ§¬ Starting architecture evolution for {self.model_config_path}...")
            
            cfg = OmegaConf.load(self.model_config_path)

            original_d_model = cfg.model.get("d_model", 128)
            original_num_layers = cfg.model.get("num_layers", 4)

            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å°‘ã—å¢—åŠ ã•ã›ã‚‹
            cfg.model.d_model = int(original_d_model * random.uniform(1.1, 1.5))
            cfg.model.num_layers = original_num_layers + random.randint(1, 2)
            
            if 'd_state' in cfg.model:
                cfg.model.d_state = int(cfg.model.d_state * 1.5)
            if 'neuron' in cfg.model and 'branch_features' in cfg.model.neuron:
                cfg.model.neuron.branch_features = cfg.model.d_model // cfg.model.neuron.get("num_branches", 4)

            print(f"   - d_model evolved: {original_d_model} -> {cfg.model.d_model}")
            print(f"   - num_layers evolved: {original_num_layers} -> {cfg.model.num_layers}")

            base_name, ext = os.path.splitext(self.model_config_path)
            new_config_path = f"{base_name}_evolved_v{self.get_next_version()}{ext}"
            
            OmegaConf.save(config=cfg, f=new_config_path)

            return f"Successfully evolved architecture. New configuration saved to '{new_config_path}'."

        except Exception as e:
            return f"Architecture evolution failed with an error: {e}"

    def _evolve_learning_parameters(self) -> str:
        """å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é€²åŒ–ã•ã›ã‚‹ã€‚"""
        if not self.training_config_path or not os.path.exists(self.training_config_path):
            return "Learning parameter evolution failed: training_config_path is not set or file not found."

        try:
            print(f"ğŸ§  Starting learning parameter evolution for {self.training_config_path}...")
            cfg = OmegaConf.load(self.training_config_path)

            params_to_evolve = [
                "training.gradient_based.learning_rate",
                "training.gradient_based.loss.spike_reg_weight",
                "training.gradient_based.loss.mem_reg_weight",
                "training.biologically_plausible.stdp.learning_rate",
                "training.biologically_plausible.stdp.tau_trace",
            ]
            
            param_key = random.choice(params_to_evolve)
            
            selected_param = OmegaConf.select(cfg, param_key)
            if selected_param is None:
                return f"Parameter '{param_key}' not found in the config. Skipping evolution."

            original_value = selected_param
            # å€¤ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«æ‘‚å‹•ã•ã›ã‚‹ (80% ~ 120%ã®ç¯„å›²)
            new_value = original_value * random.uniform(0.8, 1.2)
            
            OmegaConf.update(cfg, param_key, new_value, merge=True)

            print(f"   - Evolved parameter '{param_key}': {original_value:.6f} -> {new_value:.6f}")

            base_name, ext = os.path.splitext(self.training_config_path)
            new_config_path = f"{base_name}_evolved_v{self.get_next_version()}{ext}"
            OmegaConf.save(config=cfg, f=new_config_path)

            return f"Successfully evolved learning parameters. New configuration saved to '{new_config_path}'."

        except Exception as e:
            return f"Learning parameter evolution failed with an error: {e}"
    # â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â†‘ä¿®æ­£çµ‚ã‚ã‚Šâ—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸â—¾ï¸

    def get_next_version(self) -> int:
        # ç°¡æ˜“çš„ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
        return 2

    def run_evolution_cycle(self, task_description: str, initial_metrics: Dict[str, float]) -> None:
        """snn-cli.pyã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹ãŸã‚ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚"""
        print(f"Running evolution cycle for task: {task_description} with initial metrics: {initial_metrics}")
        
        # åˆæœŸæ€§èƒ½ã‚’è©•ä¾¡
        performance = initial_metrics.get("accuracy", 0.0)
        
        if performance < self.evolution_threshold:
            print(f"ğŸ“‰ Initial performance ({performance:.2f}) is below threshold ({self.evolution_threshold}).")
            evolution_result = self.evolve()
            print(f"âœ¨ {evolution_result}")
        else:
            print(f"âœ… Initial performance ({performance:.2f}) is sufficient. No evolution needed.")
