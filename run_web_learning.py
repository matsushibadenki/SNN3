# /run_web_learning.py
# Title: Autonomous Web Learning Script
# Description: ã‚¢ã‚¤ãƒ‰ãƒ«æ™‚ã«Webã‚’å·¡å›ã—ã€æ–°ã—ã„çŸ¥è­˜ã‚’è‡ªå¾‹çš„ã«å­¦ç¿’ã™ã‚‹ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

import argparse
from snn_research.tools.web_crawler import WebCrawler
from snn_research.distillation.knowledge_distillation_manager import KnowledgeDistillationManager

def main():
    """
    Webã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã¨ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é€£æºã•ã›ã€
    æŒ‡å®šã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå¾‹çš„ã«ç”Ÿæˆã™ã‚‹ã€‚
    """
    parser = argparse.ArgumentParser(
        description="Autonomous Web Learning Framework",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--topic",
        type=str,
        required=True,
        help="å­¦ç¿’ã•ã›ãŸã„ãƒˆãƒ”ãƒƒã‚¯ï¼ˆã‚¿ã‚¹ã‚¯åã¨ã—ã¦ä½¿ç”¨ï¼‰ã€‚\nä¾‹: 'æœ€æ–°ã®AIæŠ€è¡“'"
    )
    parser.add_argument(
        "--start_url",
        type=str,
        required=True,
        help="æƒ…å ±åé›†ã‚’é–‹å§‹ã™ã‚‹èµ·ç‚¹ã¨ãªã‚‹URLã€‚\nä¾‹: 'https://www.itmedia.co.jp/news/subtop/aiplus/'"
    )
    parser.add_argument(
        "--max_pages",
        type=int,
        default=10,
        help="åé›†ã™ã‚‹Webãƒšãƒ¼ã‚¸ã®æœ€å¤§æ•°ã€‚"
    )

    args = parser.parse_args()

    # --- ã‚¹ãƒ†ãƒƒãƒ—1: Webã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿åé›† ---
    print("\n" + "="*20 + " ğŸŒ Step 1: Web Crawling " + "="*20)
    crawler = WebCrawler()
    crawled_data_path = crawler.crawl(start_url=args.start_url, max_pages=args.max_pages)

    if not os.path.exists(crawled_data_path) or os.path.getsize(crawled_data_path) == 0:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒåé›†ã§ããªã‹ã£ãŸãŸã‚ã€å­¦ç¿’ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
        return

    # --- ã‚¹ãƒ†ãƒƒãƒ—2: ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰çŸ¥è­˜è’¸ç•™ã«ã‚ˆã‚‹å­¦ç¿’ ---
    print("\n" + "="*20 + " ğŸ§  Step 2: On-demand Learning " + "="*20)
    distillation_manager = KnowledgeDistillationManager(
        base_config_path="configs/base_config.yaml",
        model_config_path="configs/models/small.yaml" # æ–°ã—ã„å°‚é–€å®¶ã¯smallãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é–‹å§‹
    )

    distillation_manager.run_on_demand_pipeline(
        task_description=args.topic,
        unlabeled_data_path=crawled_data_path,
        teacher_model_name="gpt2", # æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¯è¨­å®šå¯èƒ½
        force_retrain=True # å¸¸ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    )

    print("\nğŸ‰ è‡ªå¾‹çš„ãªWebå­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    print(f"  ãƒˆãƒ”ãƒƒã‚¯ã€Œ{args.topic}ã€ã«é–¢ã™ã‚‹æ–°ã—ã„å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ãŒè‚²æˆã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
