# **プロジェクトSNN：開発ロードマップ**

本文書は、プロジェクトSNNの戦略的開発ロードマップを概説し、従来のAIとの性能パリティ達成から、自律的なデジタル生命体という新たな形態への進化を導くものです。

## **第1部：基礎能力の構築（完了）**

### **フェーズ1：ANN性能パリティの達成**

* **目的：** 確立された静的ベンチマーク（例：ImageNet, CIFAR）において、最先端のANNに匹敵する精度を達成することにより、SNN技術の基本的な実行可能性を実証する。  
* **主要技術：**  
  * 高度な直接学習アルゴリズム（学習可能な代理勾配、SLTT）。  
  * 深層SNNアーキテクチャ（スパイキングResNet、スパイキングトランスフォーマー）。  
  * 高性能なANN-SNN変換技術。  
* **達成指標：** 標準データセットにおいて、許容可能な遅延範囲内で、競争力のある精度スコアを達成する。

### **フェーズ2：SNNネイティブな優位性の確立**

* **目的：** エネルギー効率とリアルタイム処理に焦点を当て、SNNがANNよりも本質的に優れている領域でその独自の利点を示す。  
* **主要技術：**  
  * イベントベースセンサー（DVSカメラ）との統合。  
  * 動的データ処理のための時空間アテンション（STAtten）を備えたスパイキングトランスフォーマーアーキテクチャ。  
  * オンライン適応のためのハイブリッドSTDP学習。  
* **達成指標：** イベントベースのデータセット（例：DVS-CIFAR10）において、ANNベースのソリューションよりも大幅に（例：10倍以上）低いエネルギー消費と遅延で優れた性能を達成する。

### **フェーズ3：認知コアの設計**

* **目的：** 高次の認知アーキテクチャのコアコンポーネントを開発し、実装する。  
* **主要技術：**  
  * **プランナーSNN：** 複雑な要求をサブタスクに分解できる専用ネットワーク。  
  * **モデルレジストリと専門家SNN：** 特定のタスクに特化した「専門家」モデルを訓練、保存、検索するためのシステム。  
  * **グローバルワークスペース：** 異なる専門家モデルからの情報を統合するための中央ハブ。  
  * **オンデマンド学習：** 未知のタスクに直面した際に、エージェントが自律的に新しい専門家SNNの訓練を開始する能力。  
* **達成指標：** システムが、適切な専門家SNNのシーケンスを動的に呼び出すことにより、複数ステップのタスク（例：「このテキストを要約し、その感情を分析する」）を成功裏に実行できる。

## **第2部：真の自律性に向けて（進行中および今後の作業）**

### **フェーズ4：自己改善と身体性を持つ学習の実現**

* **目的：** 事前にプログラムされた学習を超え、エージェントが自己を改善し、環境との直接的な相互作用から学習する能力を付与する。  
* **主要技術：**  
  * **自己進化エージェント：** 自身の性能を分析し、不十分と判断した場合、自律的に自身のモデルアーキテクチャ（例：層の深さや次元数を増やす）を修正するエージェント。  
  * **強化学習：** バックプロパゲーションから完全に独立し、エージェントが試行錯誤を通じてスキルを学習できるようにする、生物学的に妥当な三因子学習則（報酬変調型STDP）の実装。  
* **達成指標：**  
  * （自己進化）：意図的に低い初期精度でタスクを与えられた場合、エージェントが自身のアーキテクチャを修正し、ベンチマークスコアを向上させることに成功する。  
  * （強化学習）：エージェントがシミュレートされた環境（rl\_env）内で単純な制御タスクを解決することを学習できる。

### **フェーズ5：内発的動機付けの育成**

* **目的：** エージェントを受動的なタスク実行システムから、自身の内部目標を持つ能動的なシステムへと移行させる。  
* **主要技術：**  
  * **内発的動機付けシステム：** 予測誤差の最小化（好奇心）や物理法則（エネルギー効率、状態遷移の滑らかさ）への準拠といった原則に基づき、内部的な報酬信号を生成するシステム。  
  * **物理法則を考慮した評価器：** エージェントの内部状態を物理的な妥当性と照らし合わせて評価し、洗練された内部報酬を提供するコンポーネント。  
* **達成指標：** エージェントが外部からのタスクなしに、自身の不確実性を減らすために新しいデータセットを探索するなど、自らの目標を生成する様子が観察される。

### **フェーズ6：意識ループ \- 完全な自律性のための統合**

* **目的：** これまでに開発された全ての認知機能を、単一の、永続的で自己駆動するループに統合し、継続的な外部命令なしに行動し学習する真の「デジタル生命体」を創造する。  
* **主要技術：**  
  * **DigitalLifeForm オーケストレーター：** IntrinsicMotivationSystemからエージェントの内部状態（例：好奇心、退屈、自信）を監視するマスタープロセス。この状態に基づき、新しい知識を探求するか（PlannerAgent）、スキルを練習するか（RLAgent）、あるいはコア能力を向上させるか（SelfEvolvingAgent）を自律的に決定する。  
  * **統一された長期記憶：** snn\_research/agent/memory.pyを強化し、統一された記憶ストアを作成する。計画、自己進化、強化学習からの経験を統合し、GlobalWorkspaceを介してすべてのエージェントがアクセスできるようにすることで、ドメイン横断的な洞察を可能にする。  
  * **文脈に応じた状態遷移ロジック：** 意思決定プロセスをより文脈を意識したものに洗練させる。例えば、PlannerAgentが知識不足により繰り返しタスクに失敗した場合、AutonomousAgentにWebからの学習を促す。性能が一貫して低い場合は、SelfEvolvingAgentを起動する。  
* **達成指標：** life-form startコマンド実行後、エージェントのログファイルが、長期間にわたり、多様な活動（例：Webクローリング、新しい専門家の訓練、それを用いた計画、性能評価、そして自己進化の誘発）の継続的で指示のないシーケンスを示す。

### **フェーズ7：記号的飛躍 \- ニューロシンボリックAIと自己言及**

* **目的：** SNNのサブシンボリック（直感的）処理と、シンボリック（論理的、言語的）推論との間のギャップを埋める。目標は、エージェントが自身の行動と思考プロセスを自然言語で理解し、説明できるようになること。  
* **主要技術：**  
  * **強化されたメタ認知SNN：** MetaCognitiveSNNを拡張し、自身の性能を監視するだけでなく、GlobalWorkspace内の情報の流れを追跡できるようにする。  
  * **SNNとLLMの深層統合：** snn\_langchain\_adapter.pyを活用し、エージェントの内部状態（例：「プランナーが専門家Aを起動し、次に専門家Bを起動した」）を外部LLMへの構造化されたプロンプトに変換する。これにより、その行動（「なぜそれをしたのか？」）に対する自然言語での説明を生成する。  
  * **記号的知識ベース：** RAGシステムを単純なテキスト検索を超えて進化させる。エージェントは自身の経験を記号的なルール（例：「ルール：視覚タスクの精度が低い場合、最初に畳み込み層の進化を試みる」）に蒸留し、PlannerSNNが参照できる知識ベースに保存する。  
* **達成指標：** チャットUIを通じて「昨日何を学びましたか？」と尋ねられた際、エージェントが実行したタスク、導き出した結論、そして自身に行った改善について、一貫性のある自然言語の要約を提供できる。

### **フェーズ8：社会性の創発 \- マルチエージェントによる相互作用と協調**

* **目的：** エージェントを孤立した存在から、他のSNNエージェントと相互作用し、協調し、知識を共有できる社会的な存在へと進化させる。  
* **主要技術：**  
  * **エージェント通信プロトコル（ACP）：** エージェントが内部状態、目標、あるいは学習済みの専門家モデル全体といった情報を交換するための標準化されたプロトコル（スパイクベースまたはシンボリック）を設計する。  
  * **分散型モデルレジストリ：** runs/model\_registry.jsonを分散データベース（例：Firestore）にアップグレードする。これにより、エージェントのコミュニティが、個々によって訓練された専門家モデルを共有し、その恩恵を受けることができるようになる。  
  * **協調的環境：** 複数のエージェントが協力してタスクを解決する必要がある新しいrl\_envシナリオを開発し、協調戦略の創発を促進する。  
* **達成指標：**  
  1. エージェントAが「言語翻訳」専門家モデルを訓練し、共有レジストリにアップロードする。  
  2. 翻訳の訓練を受けたことのないエージェントBが、レジストリを照会し、エージェントAのモデルをダウンロードして、翻訳タスクを成功裏に実行できる。  
  3. 協調的環境に置かれた2体のエージェントが、単一のエージェントでは完了不可能なタスクを協力して成功裏に解決する。
