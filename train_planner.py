# /train_planner.py
# å­¦ç¿’å¯èƒ½ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼SNN (PlannerSNN) ã‚’å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

import argparse
import os
import torch
from dependency_injector.wiring import inject, Provide
from torch.utils.data import DataLoader, Dataset
from typing import List, Dict

from app.containers import TrainingContainer
from snn_research.training.trainers import PlannerTrainer

# DIã‚³ãƒ³ãƒ†ãƒŠã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
container = TrainingContainer()

class PlannerDataset(Dataset):
    """ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼å­¦ç¿’ç”¨ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    def __init__(self, tokenizer, skill_to_id, max_len):
        self.tokenizer = tokenizer
        self.skill_to_id = skill_to_id
        self.max_len = max_len
        
        # (ä¾‹) ã€Œè¦ç´„ã€ã—ã¦ã‹ã‚‰ã€Œæ„Ÿæƒ…åˆ†æã€ã™ã‚‹ã‚¿ã‚¹ã‚¯
        self.data = [
            {
                "request": "ã“ã®æ–‡ç« ã‚’è¦ç´„ã—ã¦ã€å†…å®¹ã®æ„Ÿæƒ…ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚",
                "plan": ["æ–‡ç« è¦ç´„", "æ„Ÿæƒ…åˆ†æ"]
            },
            {
                "request": "æ°—åˆ†ã¯ã©ã†ï¼Ÿã“ã®è¨˜äº‹ã‚’åˆ†æã—ã¦è¦ç´„ã—ã¦ã€‚",
                "plan": ["æ„Ÿæƒ…åˆ†æ", "æ–‡ç« è¦ç´„"]
            }
        ]

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        item = self.data[idx]
        request = item["request"]
        plan = item["plan"]
        
        input_ids = self.tokenizer.encode(request, return_tensors='pt', max_length=self.max_len, padding='max_length', truncation=True).squeeze(0)
        
        target_ids = torch.tensor([self.skill_to_id.get(skill, -100) for skill in plan], dtype=torch.long)
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚‚å›ºå®šé•·ã«ã™ã‚‹ (ç°¡å˜ã®ãŸã‚2ã‚¹ã‚­ãƒ«ã¾ã§ã¨ä»®å®š)
        padded_target = torch.full((2,), -100, dtype=torch.long)
        padded_target[:len(target_ids)] = target_ids
        
        return input_ids, padded_target

@inject
def main(
    config=Provide[TrainingContainer.config],
    tokenizer=Provide[TrainingContainer.tokenizer]
):
    """ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼SNNã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

    # ç°¡å˜ãªã‚¹ã‚­ãƒ«è¾æ›¸ã‚’ä½œæˆ
    # æœ¬æ¥ã¯ModelRegistryã‹ã‚‰å‹•çš„ã«å–å¾—ã™ã‚‹
    skills = ["æ–‡ç« è¦ç´„", "æ„Ÿæƒ…åˆ†æ"]
    skill_to_id = {skill: i for i, skill in enumerate(skills)}

    dataset = PlannerDataset(tokenizer, skill_to_id, config.model.time_steps())
    dataloader = DataLoader(dataset, batch_size=config.training.batch_size())

    device = container.get_auto_device()
    
    # DIã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ç”¨ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å–å¾—
    planner_model = container.planner_snn(num_skills=len(skills)).to(device)
    optimizer = container.planner_optimizer(params=planner_model.parameters())
    criterion = container.planner_loss()
    
    trainer = PlannerTrainer(
        model=planner_model,
        optimizer=optimizer,
        criterion=criterion,
        device=device
    )

    for epoch in range(config.training.epochs()):
        trainer.train_epoch(dataloader, epoch)

    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    output_path = "runs/planner_snn.pth"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    torch.save(planner_model.state_dict(), output_path)
    print(f"âœ… å­¦ç¿’æ¸ˆã¿ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ '{output_path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼SNN å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument("--config", type=str, default="configs/base_config.yaml")
    parser.add_argument("--model_config", type=str, default="configs/models/small.yaml")
    args = parser.parse_args()
    
    container.config.from_yaml(args.config)
    container.config.from_yaml(args.model_config)
    container.wire(modules=[__name__])
    
    main()