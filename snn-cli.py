# /snn-cli.py
# Title: çµ±åˆCLIãƒ„ãƒ¼ãƒ«
# Description: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨æ©Ÿèƒ½ã‚’ã‚µãƒ–ã‚³ãƒžãƒ³ãƒ‰å½¢å¼ã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: å­˜åœ¨ã—ãªã„SpikingDatasetã®ä»£ã‚ã‚Šã«ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹ã‚’è¿½åŠ ã€‚
#                 åž‹ã‚¨ãƒ©ãƒ¼(DictConfig, int/float)ã‚’ä¿®æ­£ã€‚
#                 é‡è¤‡ã™ã‚‹trainé–¢æ•°ã‚’å‰Šé™¤ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®å‘¼ã³å‡ºã—ã¨å¼•æ•°ã‚’ä¿®æ­£ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: ModelRegistryã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã‚’å…·è±¡ã‚¯ãƒ©ã‚¹ã«å¤‰æ›´ã€‚
# æ”¹å–„ç‚¹: RAGSystemã‚’HierarchicalPlannerã«æ³¨å…¥ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
# mypyã‚¨ãƒ©ãƒ¼ä¿®æ­£: asyncio.run() ã‚’ä½¿ã£ã¦éžåŒæœŸé–¢æ•°ã‚’å‘¼ã³å‡ºã™ã‚ˆã†ã«ä¿®æ­£ã€‚

import argparse
import sys
import asyncio
from pathlib import Path
import os
from typing import Tuple, cast, Dict, Any
import torch
from torch.utils.data import Dataset
import typer
from omegaconf import OmegaConf, DictConfig

from snn_research.core.snn_core import SNNCore
from snn_research.training.trainers import BPTTTrainer


# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ  ---
sys.path.append(str(Path(__file__).resolve().parent))

# --- å„æ©Ÿèƒ½ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from snn_research.agent.autonomous_agent import AutonomousAgent
from snn_research.agent.self_evolving_agent import SelfEvolvingAgent
from snn_research.agent.digital_life_form import DigitalLifeForm
from snn_research.agent.reinforcement_learner_agent import ReinforcementLearnerAgent
from snn_research.cognitive_architecture.hierarchical_planner import HierarchicalPlanner
from snn_research.rl_env.simple_env import SimpleEnvironment
import train as gradient_based_trainer
from snn_research.distillation.model_registry import SimpleModelRegistry
from snn_research.agent.memory import Memory
from snn_research.tools.web_crawler import WebCrawler
from snn_research.cognitive_architecture.rag_snn import RAGSystem


app = typer.Typer()

@app.command(name="train-basic", help="[ç°¡æ˜“ç‰ˆ] BPTTãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬çš„ãªSNNãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã‚ˆã‚Šé«˜åº¦ãªæ©Ÿèƒ½ï¼ˆåˆ†æ•£å­¦ç¿’ã€è©³ç´°ãªè¨­å®šï¼‰ãŒå¿…è¦ãªå ´åˆã¯ `gradient-train` ã‚³ãƒžãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
def train_basic_command(
    config_path: str = typer.Option("configs/base_config.yaml", help="Path to the base config file."),
    model_config_path: str = typer.Option(..., help="Path to the model config file (e.g., configs/models/spiking_transformer.yaml)."),
    output_dir: str = typer.Option("models/", help="Directory to save the trained model.")
):
    """SNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
    print("--- Starting Basic Training ---")

    base_cfg = OmegaConf.load(config_path)
    model_cfg = OmegaConf.load(model_config_path)
    cfg = cast(DictConfig, OmegaConf.merge(base_cfg, model_cfg))
    print("Configuration loaded:")
    print(OmegaConf.to_yaml(cfg))

    # ç°¡æ˜“ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãŸã‚ã®ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å®šç¾©
    class _SpikingDataset(Dataset):
        def __init__(self, num_samples: int, sequence_length: int, vocab_size: int):
            self.num_samples = num_samples
            self.sequence_length = sequence_length
            self.vocab_size = vocab_size

        def __len__(self) -> int:
            return self.num_samples

        def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
            data = torch.randint(0, self.vocab_size, (self.sequence_length,))
            targets = torch.randint(0, self.vocab_size, (self.sequence_length,))
            return data, targets
            
    vocab_size = cfg.model.get("vocab_size", cfg.data.get("max_vocab_size", 50000))
    dataset = _SpikingDataset(num_samples=100, sequence_length=cfg.model.get("time_steps", 32), vocab_size=vocab_size)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=cfg.training.batch_size)
    print(f"Dataset prepared with {len(dataset)} samples.")

    model = SNNCore(cfg, vocab_size=vocab_size)
    print("Model initialized:")
    print(model)

    trainer = BPTTTrainer(model, cfg)
    print("Trainer initialized.")

    print("--- Training Loop ---")
    epochs = cfg.training.get("epochs", 1) 
    for epoch in range(epochs):
        total_loss: float = 0.0
        for i, (data, targets) in enumerate(dataloader):
            loss = trainer.train_step(data, targets)
            total_loss += loss
            if i % 10 == 0:
                print(f"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss:.4f}")
        print(f"Epoch {epoch+1} Average Loss: {total_loss / len(dataloader):.4f}")
    
    os.makedirs(output_dir, exist_ok=True)
    model_name = cfg.model.get("architecture_type", cfg.model.get("type", "snn_model"))
    save_path = os.path.join(output_dir, f"{model_name}_final.pth")
    torch.save(model.state_dict(), save_path)
    print(f"--- Training Finished ---")
    print(f"Model saved to {save_path}")
    
    
def handle_agent(args: argparse.Namespace) -> None:
    """è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹"""
    model_registry = SimpleModelRegistry()
    rag_system = RAGSystem()
    memory = Memory()
    web_crawler = WebCrawler()
    planner = HierarchicalPlanner(model_registry=model_registry, rag_system=rag_system)

    agent = AutonomousAgent(
        name="cli-agent",
        planner=planner,
        model_registry=model_registry,
        memory=memory,
        web_crawler=web_crawler,
        accuracy_threshold=args.min_accuracy,
        energy_budget=args.max_spikes
    )
    
    # éžåŒæœŸé–¢æ•°ã‚’ asyncio.run ã§å®Ÿè¡Œ
    selected_model_info = asyncio.run(agent.handle_task(
        task_description=args.task,
        unlabeled_data_path=args.unlabeled_data_path,
        force_retrain=args.force_retrain
    ))
    
    if selected_model_info and args.prompt:
        print("\n" + "="*20 + " ðŸ§  INFERENCE " + "="*20)
        print(f"å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {args.prompt}")
        asyncio.run(agent.run_inference(selected_model_info, args.prompt))
    elif not selected_model_info:
        print("\n" + "="*20 + " âŒ TASK FAILED " + "="*20)
        print("ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")


def handle_planner(args: argparse.Namespace) -> None:
    """éšŽå±¤çš„ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹"""
    model_registry = SimpleModelRegistry()
    rag_system = RAGSystem()
    planner = HierarchicalPlanner(model_registry=model_registry, rag_system=rag_system)
    
    final_result = planner.execute_task(
        task_request=args.request,
        context=args.context
    )
    if final_result:
        print("\n" + "="*20 + " âœ… FINAL RESULT " + "="*20)
        print(final_result)
    else:
        print("\n" + "="*20 + " âŒ TASK FAILED " + "="*20)

def handle_life_form(args: argparse.Namespace) -> None:
    """ãƒ‡ã‚¸ã‚¿ãƒ«ç”Ÿå‘½ä½“ã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹"""
    life_form = DigitalLifeForm()
    life_form.awareness_loop(cycles=args.cycles)

def handle_evolution(args: argparse.Namespace) -> None:
    """è‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹"""
    model_registry = SimpleModelRegistry()
    rag_system = RAGSystem()
    memory = Memory()
    web_crawler = WebCrawler()
    planner = HierarchicalPlanner(model_registry=model_registry, rag_system=rag_system)

    agent = SelfEvolvingAgent(
        name="evolving-agent",
        planner=planner,
        model_registry=model_registry,
        memory=memory,
        web_crawler=web_crawler,
        project_root=".",
        model_config_path=args.model_config
    )
    initial_metrics = {
        "accuracy": args.initial_accuracy,
        "avg_spikes_per_sample": args.initial_spikes
    }
    agent.run_evolution_cycle(
        task_description=args.task_description,
        initial_metrics=initial_metrics
    )

def handle_rl(args: argparse.Namespace) -> None:
    """ç”Ÿç‰©å­¦çš„å¼·åŒ–å­¦ç¿’ã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹"""
    import torch
    from tqdm import tqdm

    device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    env = SimpleEnvironment(pattern_size=args.pattern_size, device=device)
    agent = ReinforcementLearnerAgent(input_size=args.pattern_size, output_size=args.pattern_size, device=device)
    
    progress_bar = tqdm(range(args.episodes))
    total_reward = 0.0

    for episode in progress_bar:
        state = env.reset()
        action = agent.get_action(state)
        _, reward, _ = env.step(action)
        agent.learn(reward)
        total_reward += reward
        avg_reward = total_reward / (episode + 1)
        progress_bar.set_postfix({"Avg Reward": f"{avg_reward:.3f}"})
    
    print(f"\nâœ… å­¦ç¿’å®Œäº†ã€‚æœ€çµ‚çš„ãªå¹³å‡å ±é…¬: {total_reward / args.episodes:.4f}")

def handle_gradient_train(args: argparse.Namespace) -> None:
    """å‹¾é…ãƒ™ãƒ¼ã‚¹å­¦ç¿’ã®æ©Ÿèƒ½ã‚’å‡¦ç†ã™ã‚‹ (train.pyã‚’å‘¼ã³å‡ºã™)"""
    print("ðŸ”§ å‹¾é…ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")
    original_argv = sys.argv
    sys.argv = [original_argv[0]] + args.train_args
    gradient_based_trainer.main()
    sys.argv = original_argv

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Project SNN: çµ±åˆCLIãƒ„ãƒ¼ãƒ«",
        formatter_class=argparse.RawTextHelpFormatter
    )
    subparsers = parser.add_subparsers(dest="command", required=True, help="å®Ÿè¡Œã™ã‚‹æ©Ÿèƒ½ã‚’é¸æŠž")

    parser_agent = subparsers.add_parser("agent", help="è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ“ä½œã—ã¦å˜ä¸€ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ")
    parser_agent.add_argument("solve", help="æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ã¾ã™")
    parser_agent.add_argument("--task", type=str, required=True, help="ã‚¿ã‚¹ã‚¯ã®è‡ªç„¶è¨€èªžèª¬æ˜Ž (ä¾‹: 'æ„Ÿæƒ…åˆ†æž')")
    parser_agent.add_argument("--prompt", type=str, help="æŽ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    parser_agent.add_argument("--unlabeled_data_path", type=str, help="æ–°è¦å­¦ç¿’æ™‚ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹")
    parser_agent.add_argument("--force_retrain", action="store_true", help="ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ç°¿ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†å­¦ç¿’")
    parser_agent.add_argument("--min_accuracy", type=float, default=0.6, help="å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠžã™ã‚‹ãŸã‚ã®æœ€ä½Žç²¾åº¦è¦ä»¶ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.6)")
    parser_agent.add_argument("--max_spikes", type=float, default=10000.0, help="å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠžã™ã‚‹ãŸã‚ã®å¹³å‡ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ä¸Šé™ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10000.0)")
    parser_agent.set_defaults(func=handle_agent)

    parser_planner = subparsers.add_parser("planner", help="é«˜æ¬¡èªçŸ¥ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚’æ“ä½œã—ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ")
    parser_planner.add_argument("execute", help="è¤‡é›‘ãªã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’å®Ÿè¡Œã—ã¾ã™")
    parser_planner.add_argument("--request", type=str, required=True, help="ã‚¿ã‚¹ã‚¯è¦æ±‚ (ä¾‹: 'è¨˜äº‹ã‚’è¦ç´„ã—ã¦æ„Ÿæƒ…ã‚’åˆ†æž')")
    parser_planner.add_argument("--context", type=str, required=True, help="å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿")
    parser_planner.set_defaults(func=handle_planner)

    parser_life = subparsers.add_parser("life-form", help="ãƒ‡ã‚¸ã‚¿ãƒ«ç”Ÿå‘½ä½“ã®è‡ªå¾‹ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹")
    parser_life.add_argument("start", help="æ„è­˜ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™")
    parser_life.add_argument("--cycles", type=int, default=5, help="å®Ÿè¡Œã™ã‚‹æ„è­˜ã‚µã‚¤ã‚¯ãƒ«ã®å›žæ•°")
    parser_life.set_defaults(func=handle_life_form)

    parser_evo = subparsers.add_parser("evolve", help="è‡ªå·±é€²åŒ–ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ")
    parser_evo.add_argument("run", help="è‡ªå·±é€²åŒ–ã‚µã‚¤ã‚¯ãƒ«ã‚’1å›žå®Ÿè¡Œã—ã¾ã™")
    parser_evo.add_argument("--task_description", type=str, required=True, help="è‡ªå·±è©•ä¾¡ã®èµ·ç‚¹ã¨ãªã‚‹ã‚¿ã‚¹ã‚¯èª¬æ˜Ž")
    parser_evo.add_argument("--model_config", type=str, default="configs/models/small.yaml", help="é€²åŒ–å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«")
    parser_evo.add_argument("--initial_accuracy", type=float, default=0.75, help="è‡ªå·±è©•ä¾¡ã®ãŸã‚ã®åˆæœŸç²¾åº¦")
    parser_evo.add_argument("--initial_spikes", type=float, default=1500.0, help="è‡ªå·±è©•ä¾¡ã®ãŸã‚ã®åˆæœŸã‚¹ãƒ‘ã‚¤ã‚¯æ•°")
    parser_evo.set_defaults(func=handle_evolution)
    
    parser_rl = subparsers.add_parser("rl", help="ç”Ÿç‰©å­¦çš„å¼·åŒ–å­¦ç¿’ã‚’å®Ÿè¡Œ")
    parser_rl.add_argument("run", help="å¼·åŒ–å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™")
    parser_rl.add_argument("--episodes", type=int, default=100, help="å­¦ç¿’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°")
    parser_rl.add_argument("--pattern_size", type=int, default=10, help="ç’°å¢ƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µã‚¤ã‚º")
    parser_rl.set_defaults(func=handle_rl)

    parser_train = subparsers.add_parser("gradient-train", help="å‹¾é…ãƒ™ãƒ¼ã‚¹ã§SNNãƒ¢ãƒ‡ãƒ«ã‚’æ‰‹å‹•å­¦ç¿’ (train.pyã®å¼•æ•°ã‚’æŒ‡å®š)")
    parser_train.add_argument('train_args', nargs=argparse.REMAINDER, help="train.pyã«æ¸¡ã™å¼•æ•° (ä¾‹: --config ...)")
    parser_train.set_defaults(func=handle_gradient_train)

    args = parser.parse_args()
    args.func(args)

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == 'train':
         app()
    else:
         main()
