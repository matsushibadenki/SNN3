# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: matsushibadenki/snn3/SNN3-190ede29139f560c909685675a68ccf65069201c/snn-cli.py
#
# çµ±åˆCLIãƒ„ãƒ¼ãƒ« (typerç‰ˆ)
#
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨æ©Ÿèƒ½ã‚’ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰å½¢å¼ã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚
# argparseã¨typerã®æ··åœ¨ã«ã‚ˆã£ã¦ç™ºç”Ÿã—ã¦ã„ãŸå¼•æ•°è§£æã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€
# typerã«å®Œå…¨ã«ç§»è¡Œã€‚gradient-trainãŒè¿½åŠ ã®å¼•æ•°ã‚’æ­£ã—ã
# train.pyã«æ¸¡ã›ã‚‹ã‚ˆã†ã«ä¿®æ­£ã€‚
#
# ä¿®æ­£ç‚¹:
# - evolve runã‚³ãƒãƒ³ãƒ‰ã« --training-config ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ ã—ã€
#   SelfEvolvingAgentãŒå­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é€²åŒ–ã•ã›ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã€‚
# - uiã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã‚’è¿½åŠ ã—ã€æ¨™æº–UIã¨LangChainé€£æºUIã‚’
#   é¸æŠã—ã¦èµ·å‹•ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚
# - life-formã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã« `explain-last-action` ã‚’è¿½åŠ ã—ã€
#   AIãŒè‡ªèº«ã®è¡Œå‹•ç†ç”±ã‚’èª¬æ˜ã™ã‚‹æ©Ÿèƒ½ï¼ˆè‡ªå·±è¨€åŠï¼‰ã‚’å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ã—ãŸã€‚
# - ROADMAPãƒ•ã‚§ãƒ¼ã‚º8ã«åŸºã¥ãã€`emergent-system`ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã‚’è¿½åŠ ã€‚
# - ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹å”èª¿çš„ãªã‚¿ã‚¹ã‚¯è§£æ±ºãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚
#
# æ”¹å–„ç‚¹ (v2):
# - DigitalLifeFormã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã‚’DIã‚³ãƒ³ãƒ†ãƒŠçµŒç”±ã§è¡Œã†ã‚ˆã†ã«ä¿®æ­£ã€‚

import sys
from pathlib import Path
import asyncio
import torch
import typer
from typing import List, Optional

# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ  ---
sys.path.append(str(Path(__file__).resolve().parent))

# --- å„æ©Ÿèƒ½ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from app.containers import AgentContainer, AppContainer
from snn_research.agent.digital_life_form import DigitalLifeForm
from snn_research.agent.autonomous_agent import AutonomousAgent
from snn_research.agent.self_evolving_agent import SelfEvolvingAgent
from snn_research.agent.reinforcement_learner_agent import ReinforcementLearnerAgent
from snn_research.cognitive_architecture.hierarchical_planner import HierarchicalPlanner
from snn_research.rl_env.simple_env import SimpleEnvironment
import train as gradient_based_trainer
from snn_research.distillation.model_registry import SimpleModelRegistry
from snn_research.agent.memory import Memory
from snn_research.tools.web_crawler import WebCrawler
from snn_research.cognitive_architecture.rag_snn import RAGSystem
from snn_research.cognitive_architecture.emergent_system import EmergentCognitiveSystem
from snn_research.cognitive_architecture.global_workspace import GlobalWorkspace
import app.main as gradio_app
import app.langchain_main as langchain_gradio_app
from snn_research.cognitive_architecture.intrinsic_motivation import IntrinsicMotivationSystem
from snn_research.cognitive_architecture.meta_cognitive_snn import MetaCognitiveSNN
from snn_research.cognitive_architecture.physics_evaluator import PhysicsEvaluator
from snn_research.cognitive_architecture.symbol_grounding import SymbolGrounding

# --- CLIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®šç¾© ---
app = typer.Typer(
    help="Project SNN: çµ±åˆCLIãƒ„ãƒ¼ãƒ«",
    rich_markup_mode="markdown",
    add_completion=False
)

# --- ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ ---
agent_app = typer.Typer(help="è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ“ä½œã—ã¦å˜ä¸€ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ")
app.add_typer(agent_app, name="agent")

planner_app = typer.Typer(help="é«˜æ¬¡èªçŸ¥ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚’æ“ä½œã—ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ")
app.add_typer(planner_app, name="planner")

life_form_app = typer.Typer(help="ãƒ‡ã‚¸ã‚¿ãƒ«ç”Ÿå‘½ä½“ã®è‡ªå¾‹ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹")
app.add_typer(life_form_app, name="life-form")

evolve_app = typer.Typer(help="è‡ªå·±é€²åŒ–ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ")
app.add_typer(evolve_app, name="evolve")

rl_app = typer.Typer(help="ç”Ÿç‰©å­¦çš„å¼·åŒ–å­¦ç¿’ã‚’å®Ÿè¡Œ")
app.add_typer(rl_app, name="rl")

ui_app = typer.Typer(help="Gradioãƒ™ãƒ¼ã‚¹ã®å¯¾è©±UIã‚’èµ·å‹•")
app.add_typer(ui_app, name="ui")

emergent_app = typer.Typer(help="å‰µç™ºçš„ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ“ä½œ")
app.add_typer(emergent_app, name="emergent-system")


# --- agent ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@agent_app.command("solve", help="æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ã¾ã™ã€‚å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ã€ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å­¦ç¿’ã€æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
def agent_solve(
    task: str = typer.Option(..., help="ã‚¿ã‚¹ã‚¯ã®è‡ªç„¶è¨€èªèª¬æ˜ (ä¾‹: 'æ„Ÿæƒ…åˆ†æ')"),
    prompt: Optional[str] = typer.Option(None, help="æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹å ´åˆã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"),
    unlabeled_data: Optional[Path] = typer.Option(None, help="æ–°è¦å­¦ç¿’æ™‚ã«ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹", exists=True, file_okay=True, dir_okay=False),
    force_retrain: bool = typer.Option(False, "--force-retrain", help="ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ç°¿ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†å­¦ç¿’"),
    min_accuracy: float = typer.Option(0.6, help="å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã®æœ€ä½ç²¾åº¦è¦ä»¶"),
    max_spikes: float = typer.Option(10000.0, help="å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã‚‹ãŸã‚ã®å¹³å‡ã‚¹ãƒ‘ã‚¤ã‚¯æ•°ä¸Šé™")
):
    container = AgentContainer()
    container.config.from_yaml("configs/base_config.yaml")
    
    agent = AutonomousAgent(
        name="cli-agent",
        planner=container.hierarchical_planner(),
        model_registry=container.model_registry(),
        memory=container.memory(),
        web_crawler=container.web_crawler(),
        accuracy_threshold=min_accuracy,
        energy_budget=max_spikes
    )
    
    selected_model_info = asyncio.run(agent.handle_task(
        task_description=task,
        unlabeled_data_path=str(unlabeled_data) if unlabeled_data else None,
        force_retrain=force_retrain
    ))
    
    if selected_model_info and prompt:
        print("\n" + "="*20 + " ğŸ§  INFERENCE " + "="*20)
        print(f"å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        asyncio.run(agent.run_inference(selected_model_info, prompt))
    elif not selected_model_info:
        print("\n" + "="*20 + " âŒ TASK FAILED " + "="*20)
        print("ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

# --- planner ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@planner_app.command("execute", help="è¤‡é›‘ãªã‚¿ã‚¹ã‚¯è¦æ±‚ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚å†…éƒ¨ã§è¨ˆç”»ã‚’ç«‹æ¡ˆã—ã€è¤‡æ•°ã®å°‚é–€å®¶ã‚’é€£æºã•ã›ã¾ã™ã€‚")
def planner_execute(
    request: str = typer.Option(..., help="ã‚¿ã‚¹ã‚¯è¦æ±‚ (ä¾‹: 'è¨˜äº‹ã‚’è¦ç´„ã—ã¦æ„Ÿæƒ…ã‚’åˆ†æ')"),
    context: str = typer.Option(..., help="å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿")
):
    container = AgentContainer()
    container.config.from_yaml("configs/base_config.yaml")
    planner = container.hierarchical_planner()
    
    final_result = planner.execute_task(task_request=request, context=context)
    if final_result:
        print("\n" + "="*20 + " âœ… FINAL RESULT " + "="*20)
        print(final_result)
    else:
        print("\n" + "="*20 + " âŒ TASK FAILED " + "="*20)

# --- life-form ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
def get_life_form_instance() -> DigitalLifeForm:
    """DIã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ç”¨ã—ã¦DigitalLifeFormã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    agent_container = AgentContainer()
    agent_container.config.from_yaml("configs/base_config.yaml")
    app_container = AppContainer()
    app_container.config.from_yaml("configs/base_config.yaml")

    planner = agent_container.hierarchical_planner()
    model_registry = agent_container.model_registry()
    memory = agent_container.memory()
    web_crawler = agent_container.web_crawler()
    rag_system = agent_container.rag_system()

    autonomous_agent = AutonomousAgent(
        name="AutonomousAgent", planner=planner, model_registry=model_registry, 
        memory=memory, web_crawler=web_crawler
    )
    rl_agent = ReinforcementLearnerAgent(input_size=10, output_size=4, device="cpu")
    self_evolving_agent = SelfEvolvingAgent(
        name="SelfEvolvingAgent", planner=planner, model_registry=model_registry, 
        memory=memory, web_crawler=web_crawler
    )
    
    return DigitalLifeForm(
        autonomous_agent=autonomous_agent,
        rl_agent=rl_agent,
        self_evolving_agent=self_evolving_agent,
        motivation_system=IntrinsicMotivationSystem(),
        meta_cognitive_snn=MetaCognitiveSNN(),
        memory=memory,
        physics_evaluator=PhysicsEvaluator(),
        symbol_grounding=SymbolGrounding(rag_system),
        app_container=app_container
    )

@life_form_app.command("start", help="æ„è­˜ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™ã€‚AIãŒè‡ªå¾‹çš„ã«æ€è€ƒãƒ»å­¦ç¿’ã—ã¾ã™ã€‚")
def life_form_start(cycles: int = typer.Option(5, help="å®Ÿè¡Œã™ã‚‹æ„è­˜ã‚µã‚¤ã‚¯ãƒ«ã®å›æ•°")):
    life_form = get_life_form_instance()
    life_form.awareness_loop(cycles=cycles)

@life_form_app.command("explain-last-action", help="AIè‡ªèº«ã«ã€ç›´è¿‘ã®è¡Œå‹•ç†ç”±ã‚’è‡ªç„¶è¨€èªã§èª¬æ˜ã•ã›ã¾ã™ã€‚")
def life_form_explain():
    print("ğŸ¤” AIã«è‡ªèº«ã®è¡Œå‹•ç†ç”±ã‚’èª¬æ˜ã•ã›ã¾ã™...")
    life_form = get_life_form_instance()
    explanation = life_form.explain_last_action()
    print("\n" + "="*20 + " ğŸ¤– AIã«ã‚ˆã‚‹è‡ªå·±è§£èª¬ " + "="*20)
    if explanation:
        print(explanation)
    else:
        print("èª¬æ˜ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    print("="*64)

# --- evolve ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@evolve_app.command("run", help="è‡ªå·±é€²åŒ–ã‚µã‚¤ã‚¯ãƒ«ã‚’1å›å®Ÿè¡Œã—ã¾ã™ã€‚AIãŒè‡ªèº«ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ”¹å–„ã—ã¾ã™ã€‚")
def evolve_run(
    task_description: str = typer.Option(..., help="è‡ªå·±è©•ä¾¡ã®èµ·ç‚¹ã¨ãªã‚‹ã‚¿ã‚¹ã‚¯èª¬æ˜"),
    training_config: Path = typer.Option("configs/base_config.yaml", help="é€²åŒ–å¯¾è±¡ã®åŸºæœ¬è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«", exists=True),
    model_config: Path = typer.Option("configs/models/small.yaml", help="é€²åŒ–å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«", exists=True),
    initial_accuracy: float = typer.Option(0.75, help="è‡ªå·±è©•ä¾¡ã®ãŸã‚ã®åˆæœŸç²¾åº¦"),
    initial_spikes: float = typer.Option(1500.0, help="è‡ªå·±è©•ä¾¡ã®ãŸã‚ã®åˆæœŸã‚¹ãƒ‘ã‚¤ã‚¯æ•°")
):
    container = AgentContainer()
    container.config.from_yaml(str(training_config))
    container.config.from_yaml(str(model_config))

    agent = SelfEvolvingAgent(
        name="evolving-agent",
        planner=container.hierarchical_planner(),
        model_registry=container.model_registry(),
        memory=container.memory(),
        web_crawler=container.web_crawler(),
        project_root=".",
        model_config_path=str(model_config),
        training_config_path=str(training_config)
    )
    initial_metrics = {
        "accuracy": initial_accuracy,
        "avg_spikes_per_sample": initial_spikes
    }
    agent.run_evolution_cycle(
        task_description=task_description,
        initial_metrics=initial_metrics
    )

# --- rl ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@rl_app.command("run", help="å¼·åŒ–å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè©¦è¡ŒéŒ¯èª¤ã‹ã‚‰å­¦ç¿’ã—ã¾ã™ã€‚")
def rl_run(
    episodes: int = typer.Option(100, help="å­¦ç¿’ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°"),
    pattern_size: int = typer.Option(10, help="ç’°å¢ƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µã‚¤ã‚º")
):
    from tqdm import tqdm
    
    device = "mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu"
    env = SimpleEnvironment(pattern_size=pattern_size, device=device)
    agent = ReinforcementLearnerAgent(input_size=pattern_size, output_size=pattern_size, device=device)
    
    progress_bar = tqdm(range(episodes))
    total_reward = 0.0

    for episode in progress_bar:
        state = env.reset()
        action = agent.get_action(state)
        _, reward, _ = env.step(action)
        agent.learn(reward)
        total_reward += reward
        avg_reward = total_reward / (episode + 1)
        progress_bar.set_postfix({"Avg Reward": f"{avg_reward:.3f}"})
    
    print(f"\nâœ… å­¦ç¿’å®Œäº†ã€‚æœ€çµ‚çš„ãªå¹³å‡å ±é…¬: {total_reward / episodes:.4f}")


# --- ui ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@ui_app.command("start", help="æ¨™æº–ã®Gradio UIã‚’èµ·å‹•ã—ã¾ã™ã€‚")
def ui_start(
    model_config: Path = typer.Option("configs/models/small.yaml", help="ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«", exists=True),
    model_path: Optional[str] = typer.Option(None, help="ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãï¼‰"),
):
    original_argv = sys.argv
    sys.argv = [
        "app/main.py",
        "--model_config", str(model_config),
    ]
    if model_path:
        sys.argv.extend(["--model_path", model_path])
    
    try:
        print("ğŸš€ æ¨™æº–ã®Gradio UIã‚’èµ·å‹•ã—ã¾ã™...")
        gradio_app.main()
    finally:
        sys.argv = original_argv

@ui_app.command("start-langchain", help="LangChainé€£æºç‰ˆã®Gradio UIã‚’èµ·å‹•ã—ã¾ã™ã€‚")
def ui_start_langchain(
    model_config: Path = typer.Option("configs/models/small.yaml", help="ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«", exists=True),
    model_path: Optional[str] = typer.Option(None, help="ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãï¼‰"),
):
    original_argv = sys.argv
    sys.argv = [
        "app/langchain_main.py",
        "--model_config", str(model_config),
    ]
    if model_path:
        sys.argv.extend(["--model_path", model_path])

    try:
        print("ğŸš€ LangChainé€£æºç‰ˆã®Gradio UIã‚’èµ·å‹•ã—ã¾ã™...")
        langchain_gradio_app.main()
    finally:
        sys.argv = original_argv

# --- emergent-system ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@emergent_app.command("execute", help="é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã‚’ä¸ãˆã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«å”èª¿çš„ã«è§£æ±ºã•ã›ã¾ã™ã€‚")
def emergent_execute(
    goal: str = typer.Option(..., help="ã‚·ã‚¹ãƒ†ãƒ ã«é”æˆã•ã›ãŸã„é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™")
):
    print(f"ğŸš€ Emergent System Activated. Goal: {goal}")

    container = AgentContainer()
    container.config.from_yaml("configs/base_config.yaml")

    planner = container.hierarchical_planner()
    model_registry = container.model_registry()
    memory = container.memory()
    web_crawler = container.web_crawler()
    
    global_workspace = GlobalWorkspace(model_registry=model_registry)

    agent1 = AutonomousAgent(name="AutonomousAgent", planner=planner, model_registry=model_registry, memory=memory, web_crawler=web_crawler)
    agent2 = AutonomousAgent(name="SpecialistAgent", planner=planner, model_registry=model_registry, memory=memory, web_crawler=web_crawler)
    
    emergent_system = EmergentCognitiveSystem(
        planner=planner,
        agents=[agent1, agent2],
        global_workspace=global_workspace,
        model_registry=model_registry
    )

    final_report = emergent_system.execute_task(goal)

    print("\n" + "="*20 + " âœ… FINAL REPORT " + "="*20)
    print(final_report)
    print("="*60)

# --- gradient-train ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè£… ---
@app.command(
    "gradient-train",
    help="""
    å‹¾é…ãƒ™ãƒ¼ã‚¹ã§SNNãƒ¢ãƒ‡ãƒ«ã‚’æ‰‹å‹•å­¦ç¿’ã—ã¾ã™ (train.pyã‚’å‘¼ã³å‡ºã—ã¾ã™)ã€‚
    ã“ã®ã‚³ãƒãƒ³ãƒ‰ã®å¾Œã«ã€train.pyã«æ¸¡ã—ãŸã„å¼•æ•°ã‚’ãã®ã¾ã¾ç¶šã‘ã¦ãã ã•ã„ã€‚
    
    ä¾‹: `python snn-cli.py gradient-train --model_config configs/models/large.yaml --data_path data/sample_data.jsonl`
    """,
    context_settings={"allow_extra_args": True, "ignore_unknown_options": True}
)
def gradient_train(ctx: typer.Context):
    print("ğŸ”§ å‹¾é…ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’é–‹å§‹ã—ã¾ã™...")
    train_args = ctx.args
    
    original_argv = sys.argv
    sys.argv = ["train.py"] + train_args
    
    try:
        gradient_based_trainer.main()
    finally:
        sys.argv = original_argv


if __name__ == "__main__":
    app()
